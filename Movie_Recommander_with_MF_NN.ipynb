{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import ndcg_score\n",
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "id": "UFbVjvg_JtmC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preprocessing"
      ],
      "metadata": {
        "id": "NLdAPmsUXOVB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9t45jgkjm4eT",
        "outputId": "1770aa4b-fb8b-418b-d327-bd1554c3d67d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading movielens data...\n"
          ]
        }
      ],
      "source": [
        "print(\"Downloading movielens data...\")\n",
        "from urllib.request import urlretrieve\n",
        "import zipfile\n",
        "\n",
        "# Download the data\n",
        "urlretrieve(\"http://files.grouplens.org/datasets/movielens/ml-20m.zip\", \"movielens.zip\")\n",
        "zip_ref = zipfile.ZipFile('movielens.zip', \"r\")\n",
        "zip_ref.extractall()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load in the data\n",
        "df = pd.read_csv('ml-20m/ratings.csv')"
      ],
      "metadata": {
        "id": "94nkxGT1RXxP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6mBuNqRLpvIG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "d3cc84b7-b71a-43c0-fa7c-ce0907f0a28d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   userId  movieId  rating   timestamp\n",
              "0       1        2     3.5  1112486027\n",
              "1       1       29     3.5  1112484676\n",
              "2       1       32     3.5  1112484819\n",
              "3       1       47     3.5  1112484727\n",
              "4       1       50     3.5  1112484580"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8e340daf-b59c-4dbb-8230-ceb03bad91ac\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1112486027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1112484676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1112484819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1112484727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1112484580</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e340daf-b59c-4dbb-8230-ceb03bad91ac')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8e340daf-b59c-4dbb-8230-ceb03bad91ac button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8e340daf-b59c-4dbb-8230-ceb03bad91ac');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bs = 128\n",
        "reg = 0. # regularization penalty\n"
      ],
      "metadata": {
        "id": "1SweopEqGg7X"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Customize dataset\n",
        "N = df.userId.max() + 1 # number of users\n",
        "M = df.movieId.max() + 1 # number of movies\n",
        "\n",
        "# split into train and test\n",
        "df = shuffle(df)\n",
        "df = df.iloc[:1000000]\n",
        "cutoff = int(0.8*len(df))\n",
        "cutoffeval = int(0.9*len(df))\n",
        "df_train = df.iloc[:cutoff]\n",
        "df_eval = df.iloc[cutoff:cutoffeval]\n",
        "df_test = df.iloc[cutoffeval:]\n",
        "\n",
        "# initialize variables\n",
        "K = 10 # latent dimensionality\n",
        "mu = df_train.rating.mean()\n"
      ],
      "metadata": {
        "id": "6ckgRCtYSHLQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6rxQ74x5rZrb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64792b72-14a0-4844-9493-0437903c5a6e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(138494, 131263, 10, 800000, 1000000, 3.52558625)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "N,M,K,len(df_train),len(df), mu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ratingdataset(Dataset):\n",
        "  def __init__(self, df):\n",
        "    self.df = df\n",
        "    self.u = df.userId.values\n",
        "    self.m = df.movieId.values\n",
        "    self.r = df.rating.values\n",
        "    self.N = self.u.max() + 1\n",
        "    self.M = self.m.max() + 1\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.u)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    return [self.u[idx], self.m[idx]], self.r[idx]\n"
      ],
      "metadata": {
        "id": "_FEd3bmkAR8p"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratingData_train = ratingdataset(df_train)\n",
        "ratingData_eval = ratingdataset(df_eval)\n",
        "ratingData_test = ratingdataset(df_test)"
      ],
      "metadata": {
        "id": "hTn6R9OKBtN1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(ratingData_train, batch_size=bs, shuffle=True)\n",
        "eval_dataloader = DataLoader(ratingData_eval, batch_size=bs, shuffle=True)\n",
        "test_dataloader = DataLoader(ratingData_test, batch_size=bs, shuffle=True)"
      ],
      "metadata": {
        "id": "QU9a8sE390Bi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader, eval_dataloader, test_dataloader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UE7uTV8wXXTa",
        "outputId": "9fae9d40-289f-472a-ed3d-a002f6452588"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x7efde694c310>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x7efde694c250>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x7efde694c510>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_bHnIbyDr_hV"
      },
      "outputs": [],
      "source": [
        "# # direct data\n",
        "# users = torch.tensor(df_train.userId.values)\n",
        "# items = torch.tensor(df_train.movieId.values)\n",
        "# ratings = torch.tensor(df_train.rating.values)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "o3jYDgMr74El"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "BBeas35o33I1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "767a4d17-ee66-4b27-fad9-480e716999d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UserItemEmbeddingNNNet(\n",
            "  (u): Embedding(138494, 10)\n",
            "  (m): Embedding(131263, 10)\n",
            "  (u_bias): Embedding(138494, 1)\n",
            "  (m_bias): Embedding(131263, 1)\n",
            "  (lout): Linear(in_features=20, out_features=400, bias=True)\n",
            "  (act): ReLU()\n",
            "  (out): Linear(in_features=400, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        ", models\n",
        "class UserItemEmbeddingNNNet(torch.nn.Module):\n",
        "    def __init__(self, n_users, n_items, k_factors):\n",
        "\n",
        "        super(UserItemEmbeddingNNNet, self).__init__()\n",
        "        self.u = torch.nn.Embedding(n_users, k_factors)\n",
        "        self.m = torch.nn.Embedding(n_items, k_factors)\n",
        "        self.u_bias = torch.nn.Embedding(n_users, 1)\n",
        "        self.m_bias = torch.nn.Embedding(n_items, 1)\n",
        "        self.lout = torch.nn.Linear(2*k_factors, 400)\n",
        "        self.act = torch.nn.ReLU()\n",
        "        self.out = torch.nn.Linear(400,1)\n",
        "\n",
        "\n",
        "    def forward(self, users, items):\n",
        "        uembed = self.u(users)\n",
        "        membed = self.m(items)\n",
        "        ubias = self.u_bias(users)\n",
        "        mbias = self.m_bias(items)\n",
        "        umdot = torch.mul(uembed,membed)\n",
        "        umdot = torch.sum(umdot,1)\n",
        "        umdot = torch.reshape(umdot, (umdot.shape[0], 1))\n",
        "        # umcat = torch.cat((uembed.clone().detach(),membed.clone().detach()), 1)\n",
        "        umcat = torch.cat((uembed,membed), 1)\n",
        "        umcat = self.lout(umcat)\n",
        "        umcat = self.act(umcat)\n",
        "        umcat = self.out(umcat)\n",
        "        output = torch.add(umdot, umcat)\n",
        "        # output = umdot\n",
        "        output = torch.add(output, ubias)\n",
        "        output = torch.add(output, mbias)\n",
        "        # or use: result = torch.sum(torch.stack([x, y, ...]), dim=0)\n",
        "        output = torch.flatten(output)\n",
        "        return output\n",
        "\n",
        "model = UserItemEmbeddingNNNet(N, M, K)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "i8cej51N7mQg"
      },
      "outputs": [],
      "source": [
        "epochs = 30\n",
        "lr = 0.05\n",
        "min_valid_loss = np.inf\n",
        "loss_func = torch.nn.MSELoss()\n",
        "\n",
        "def train_loop(epoch, min_valid_loss, loss_func, model):\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "    train_loss = 0.0\n",
        "    model.train()\n",
        "    \n",
        "    for i, data in tqdm(enumerate(train_dataloader)):\n",
        "        inputs, labels = data\n",
        "        if torch.cuda.is_available():\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "        users, items = inputs[0], inputs[1]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        target = model(users, items)\n",
        "        loss = loss_func(target.float(), labels.float())\n",
        "        #loss = loss_func(target, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "    \n",
        "    valid_loss = 0.0\n",
        "    model.eval()     # Optional when not using model Specific layer\n",
        "    for data in eval_dataloader:\n",
        "        inputs, labels = data\n",
        "        if torch.cuda.is_available():\n",
        "            inputs, labels =inputs.cuda(), labels.cuda()\n",
        "        users, items = inputs[0], inputs[1]\n",
        "        target = model(users, items)\n",
        "        loss = loss_func(target.float(), labels.float())\n",
        "        valid_loss += loss.item() * len(inputs)\n",
        "\n",
        "    if epoch%1==0:\n",
        "        print(f'Epoch {epoch+1} \\t\\t Training Loss: {train_loss, train_loss / len(train_dataloader)} \\t\\t Validation Loss: {valid_loss, valid_loss / len(eval_dataloader)}')\n",
        "    if min_valid_loss > valid_loss:\n",
        "        print(f\"Validation Loss Decreased({min_valid_loss:.6f}--->{valid_loss:.6f})\")\n",
        "        min_valid_loss = valid_loss\n",
        "        # Saving State Dict\n",
        "        torch.save(model.state_dict(), 'saved_model.pth')\n",
        "    return min_valid_loss\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "TamNbpIn77fF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "f_Gc8h-P7mEF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8aa928b0-3dd4-45ba-ffe8-df9890233fd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6250it [00:59, 104.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 \t\t Training Loss: (19104.721152305603, 3.0567553843688966) \t\t Validation Loss: (3711.959711790085, 4.746751549603689)\n",
            "Validation Loss Decreased(inf--->3711.959712)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6250it [00:58, 106.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 \t\t Training Loss: (13618.610536575317, 2.178977685852051) \t\t Validation Loss: (3129.3096187114716, 4.001674704234619)\n",
            "Validation Loss Decreased(3711.959712--->3129.309619)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6250it [01:07, 92.54it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 \t\t Training Loss: (11582.888159513474, 1.8532621055221559) \t\t Validation Loss: (2941.721385240555, 3.7617920527372823)\n",
            "Validation Loss Decreased(3129.309619--->2941.721385)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6250it [01:00, 104.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 \t\t Training Loss: (10242.486230134964, 1.6387977968215943) \t\t Validation Loss: (2739.531768321991, 3.5032375553989654)\n",
            "Validation Loss Decreased(2941.721385--->2739.531768)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6250it [01:00, 103.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 \t\t Training Loss: (9318.935917913914, 1.4910297468662261) \t\t Validation Loss: (2439.926154613495, 3.120110172140019)\n",
            "Validation Loss Decreased(2739.531768--->2439.926155)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6250it [00:59, 105.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 \t\t Training Loss: (8598.378878116608, 1.3757406204986573) \t\t Validation Loss: (2304.460342168808, 2.9468802329524397)\n",
            "Validation Loss Decreased(2439.926155--->2304.460342)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6250it [01:02, 99.85it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 \t\t Training Loss: (8066.823098361492, 1.2906916957378387) \t\t Validation Loss: (2293.6280349493027, 2.9330281776845304)\n",
            "Validation Loss Decreased(2304.460342--->2293.628035)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6250it [01:00, 102.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 \t\t Training Loss: (7604.491394281387, 1.216718623085022) \t\t Validation Loss: (2179.7109602689743, 2.787354169141911)\n",
            "Validation Loss Decreased(2293.628035--->2179.710960)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6250it [01:01, 101.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 \t\t Training Loss: (7246.4050016999245, 1.159424800271988) \t\t Validation Loss: (2079.468311905861, 2.659166639265807)\n",
            "Validation Loss Decreased(2179.710960--->2079.468312)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6250it [01:01, 101.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 \t\t Training Loss: (6913.38003629446, 1.1061408058071136) \t\t Validation Loss: (2076.1534378528595, 2.654927669888567)\n",
            "Validation Loss Decreased(2079.468312--->2076.153438)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6250it [01:01, 102.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 \t\t Training Loss: (6656.185852944851, 1.0649897364711762) \t\t Validation Loss: (1973.7055970430374, 2.5239202008222983)\n",
            "Validation Loss Decreased(2076.153438--->1973.705597)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6250it [01:00, 103.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 \t\t Training Loss: (6412.94257992506, 1.0260708127880096) \t\t Validation Loss: (1917.1438838243484, 2.4515906442766604)\n",
            "Validation Loss Decreased(1973.705597--->1917.143884)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6250it [01:00, 103.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 \t\t Training Loss: (6196.944331109524, 0.9915110929775238) \t\t Validation Loss: (1909.4216879606247, 2.4417157135046352)\n",
            "Validation Loss Decreased(1917.143884--->1909.421688)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6250it [01:01, 102.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 \t\t Training Loss: (6016.4717400074005, 0.9626354784011841) \t\t Validation Loss: (1915.928909420967, 2.4500369685690115)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6250it [00:59, 104.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 \t\t Training Loss: (5851.631177783012, 0.9362609884452819) \t\t Validation Loss: (1844.4686324596405, 2.3586555402297193)\n",
            "Validation Loss Decreased(1909.421688--->1844.468632)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6250it [01:00, 103.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 \t\t Training Loss: (5700.662489384413, 0.9121059983015061) \t\t Validation Loss: (1872.5964572429657, 2.394624625630391)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6250it [01:00, 103.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 \t\t Training Loss: (5565.370525598526, 0.8904592840957641) \t\t Validation Loss: (1830.5692011117935, 2.3408813313450043)\n",
            "Validation Loss Decreased(1844.468632--->1830.569201)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6250it [01:00, 102.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 \t\t Training Loss: (5443.453827142715, 0.8709526123428345) \t\t Validation Loss: (1776.1281238794327, 2.271263585523571)\n",
            "Validation Loss Decreased(1830.569201--->1776.128124)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6250it [01:00, 103.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 \t\t Training Loss: (5319.191139161587, 0.8510705822658539) \t\t Validation Loss: (1784.5261439085007, 2.282002741570973)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6250it [01:00, 102.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 \t\t Training Loss: (5218.888403058052, 0.8350221444892884) \t\t Validation Loss: (1766.8184914588928, 2.2593586847300418)\n",
            "Validation Loss Decreased(1776.128124--->1766.818491)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6250it [01:00, 103.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21 \t\t Training Loss: (5116.717197060585, 0.8186747515296936) \t\t Validation Loss: (1742.8624116182327, 2.228724311532267)\n",
            "Validation Loss Decreased(1766.818491--->1742.862412)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6250it [01:01, 101.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22 \t\t Training Loss: (5019.731088101864, 0.8031569740962983) \t\t Validation Loss: (1743.4509890079498, 2.2294769680408564)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6250it [01:00, 103.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23 \t\t Training Loss: (4936.521913647652, 0.7898435061836243) \t\t Validation Loss: (1723.3388208150864, 2.203758082883742)\n",
            "Validation Loss Decreased(1742.862412--->1723.338821)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6250it [01:00, 102.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24 \t\t Training Loss: (4856.360728472471, 0.7770177165555954) \t\t Validation Loss: (1723.86923122406, 2.2044363570640155)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6250it [01:00, 103.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25 \t\t Training Loss: (4777.567641675472, 0.7644108226680756) \t\t Validation Loss: (1690.3916329145432, 2.1616261290467302)\n",
            "Validation Loss Decreased(1723.338821--->1690.391633)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6250it [01:01, 102.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26 \t\t Training Loss: (4708.327015191317, 0.7533323224306107) \t\t Validation Loss: (1696.6924525499344, 2.1696834431584837)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6250it [01:00, 102.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27 \t\t Training Loss: (4634.938100129366, 0.7415900960206986) \t\t Validation Loss: (1687.0881880521774, 2.1574017750027843)\n",
            "Validation Loss Decreased(1690.391633--->1687.088188)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6250it [01:00, 102.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28 \t\t Training Loss: (4576.343933850527, 0.7322150294160843) \t\t Validation Loss: (1673.5922901630402, 2.140143593558875)\n",
            "Validation Loss Decreased(1687.088188--->1673.592290)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6250it [01:00, 103.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29 \t\t Training Loss: (4511.880024522543, 0.7219008039236069) \t\t Validation Loss: (1697.8949502706528, 2.171221164028968)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "6250it [01:01, 102.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30 \t\t Training Loss: (4451.84169331193, 0.7122946709299087) \t\t Validation Loss: (1680.4866058826447, 2.148959854069878)\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs):\n",
        "    min_valid_loss = train_loop(epoch, min_valid_loss, loss_func, model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation\n",
        "\n",
        "### Will evaluate the performance of the model using nDCG@k metric."
      ],
      "metadata": {
        "id": "1aFv0UOW67Ys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tusers = torch.tensor(df_test.userId.values)\n",
        "titems = torch.tensor(df_test.movieId.values)"
      ],
      "metadata": {
        "id": "dQbDP-BbLSKL"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bestmodel = UserItemEmbeddingNNNet(N, M, K)\n",
        "# bestmodel.load_state_dict(torch.load('saved_model.pth'))\n",
        "# bestmodel.eval()\n",
        "# tpredsbest = bestmodel(tusers, titems)"
      ],
      "metadata": {
        "id": "CvA7t2ss5kjB"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "tpreds = model(tusers, titems)\n",
        "tpreds = tpreds.detach().numpy()"
      ],
      "metadata": {
        "id": "yEf0uQYtKo4w"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tusersnp = tusers.detach().numpy()\n",
        "titemsnp = titems.detach().numpy()\n",
        "tratings = df_test.rating.values\n",
        "tratings = (tratings*2).astype(int)\n",
        "\n",
        "def getUmapImap(tusersnp, titemsnp, tratings, tpreds):\n",
        "  usermap = {}\n",
        "  itemmap = {}\n",
        "\n",
        "  for umrp in zip(tusersnp, titemsnp, tratings, tpreds):\n",
        "    u,m,r,p = umrp[0], umrp[1], umrp[2], umrp[3]\n",
        "    if u not in usermap:\n",
        "        usermap[u] = [(m,r,p)]\n",
        "    else:\n",
        "      usermap[u] += [(m,r,p)]\n",
        "\n",
        "    if m not in itemmap:\n",
        "        itemmap[m] = [(u,r,p)]\n",
        "    else:\n",
        "      itemmap[m] += [(u,r,p)]\n",
        "\n",
        "  return usermap, itemmap\n",
        "\n",
        "usermap, itemmap = getUmapImap(tusersnp, titemsnp, tratings, tpreds)\n",
        "\n",
        "usercount = []\n",
        "for u,v in usermap.items():\n",
        "  usercount.append((u, len(v)))\n",
        "\n",
        "itemcount = []\n",
        "for u,v in itemmap.items():\n",
        "  itemcount.append((u, len(v)))\n",
        "usercount = sorted(usercount, key=lambda k: k[1])\n",
        "itemcount = sorted(itemcount, key=lambda k: k[1])\n",
        "print(usercount[51700], usercount[-1], len(usercount))\n",
        "print(itemcount[6500], itemcount[-1], len(itemcount))\n"
      ],
      "metadata": {
        "id": "R1AMfVXKLaVS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dba5e6b-1e01-4015-e813-ef0b506b92b6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(92637, 10) (118205, 44) 52065\n",
            "(3261, 11) (296, 340) 8448\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### In the test set, only ~500 user have rated more than 10 movies.\n",
        "#### For the item part, nearly 2000 movies have been rated by more than 10 users.\n",
        "#### We will do an nDCG@k metric evaluation for different thresholds."
      ],
      "metadata": {
        "id": "lNKJNA79P-9q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "> nDCG@k"
      ],
      "metadata": {
        "id": "sbOPfyo77riQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def nDCGtk(usermap, threshold):\n",
        "\n",
        "  nDCGatk = 0\n",
        "  n = 0\n",
        "  for u,v in usermap.items():\n",
        "    if len(v) > threshold:\n",
        "      labels = np.array([[m[1] for m in v]])\n",
        "      preds = np.array([[m[2] for m in v]])\n",
        "      nDCGatk += ndcg_score(labels, preds)\n",
        "      n += 1\n",
        "  return nDCGatk/n\n",
        "\n",
        "\n",
        "print(\"for users who rated 5 movies or more: \", nDCGtk(usermap, 5))\n",
        "print(\"for users who rated 10 movies or more: \", nDCGtk(usermap, 10))\n",
        "print(\"for users who rated 20 movies or more: \", nDCGtk(usermap, 20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YErn3-4hhSRs",
        "outputId": "5d82cce3-4265-475b-9a4c-124813464925"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for users who rated 5 movies or more:  0.9473262273576568\n",
            "for users who rated 10 movies or more:  0.9377138965134775\n",
            "for users who rated 20 movies or more:  0.9273918161562738\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The score above is high because we didn't really do the nearest neighbour search in the full movie category, but just ranked on the movies that the users rated.\n",
        "\n",
        "Test on an untrained model:"
      ],
      "metadata": {
        "id": "VP3PvQEqXoXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "randommodel = UserItemEmbeddingNNNet(N, M, K)\n",
        "tpredsrandom = randommodel(tusers, titems)\n",
        "tpredsrandom = tpredsrandom.detach().numpy()"
      ],
      "metadata": {
        "id": "CKurmakkUd0h"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "usermap, itemmap = getUmapImap(tusersnp, titemsnp, tratings, tpredsrandom)\n",
        "\n",
        "print(\"(Untrained) for users who rated 5 movies or more: \", nDCGtk(usermap, 5))\n",
        "print(\"(Untrained) for users who rated 10 movies or more: \", nDCGtk(usermap, 10))\n",
        "print(\"(Untrained) for users who rated 50 movies or more: \", nDCGtk(usermap, 20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "og5xZd-nYG-W",
        "outputId": "759615b9-6149-4e9c-a8c1-d031e97ecf57"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Untrained) for users who rated 5 movies or more:  0.9203125822466507\n",
            "(Untrained) for users who rated 10 movies or more:  0.9136617249919924\n",
            "(Untrained) for users who rated 50 movies or more:  0.9177193769121238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DDQqMENEY48U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QXMJcG1qZT9Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}